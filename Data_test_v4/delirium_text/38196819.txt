38196819|t|Multitask and Transfer Learning Approach for Joint Classification and Severity Estimation of Dysphonia.
38196819|a|OBJECTIVE: Despite speech being the primary communication medium, it carries valuable information about a speaker's health, emotions, and identity. Various conditions can affect the vocal organs, leading to speech difficulties. Extensive research has been conducted by voice clinicians and academia in speech analysis. Previous approaches primarily focused on one particular task, such as differentiating between normal and dysphonic speech, classifying different voice disorders, or estimating the severity of voice disorders. METHODS AND PROCEDURES: This study proposes an approach that combines transfer learning and multitask learning (MTL) to simultaneously perform dysphonia classification and severity estimation. Both tasks use a shared representation; network is learned from these shared features. We employed five computer vision models and changed their architecture to support multitask learning. Additionally, we conducted binary 'healthy vs. dysphonia' and multiclass 'healthy vs. organic and functional dysphonia' classification using multitask learning, with the speaker's sex as an auxiliary task. RESULTS: The proposed method achieved improved performance across all classification metrics compared to single-task learning (STL), which only performs classification or severity estimation. Specifically, the model achieved F1 scores of 93% and 90% in MTL and STL, respectively. Moreover, we observed considerable improvements in both classification tasks by evaluating beta values associated with the weight assigned to the sex-predicting auxiliary task. MTL achieved an accuracy of 77% compared to the STL score of 73.2%. However, the performance of severity estimation in MTL was comparable to STL. CONCLUSION: Our goal is to improve how voice pathologists and clinicians understand patients' conditions, make it easier to track their progress, and enhance the monitoring of vocal quality and treatment procedures. Clinical and Translational Impact Statement: By integrating both classification and severity estimation of dysphonia using multitask learning, we aim to enable clinicians to gain a better understanding of the patient's situation, effectively monitor their progress and voice quality.
38196819	93	102	Dysphonia	Disease	MESH:D055154
38196819	528	537	dysphonic	Disease	
38196819	568	583	voice disorders	Disease	MESH:D014832
38196819	615	630	voice disorders	Disease	MESH:D014832
38196819	775	784	dysphonia	Disease	MESH:D055154
38196819	1061	1070	dysphonia	Disease	MESH:D055154
38196819	1123	1132	dysphonia	Disease	MESH:D055154
38196819	1907	1915	patients	Species	9606
38196819	2146	2155	dysphonia	Disease	MESH:D055154
38196819	2248	2255	patient	Species	9606

